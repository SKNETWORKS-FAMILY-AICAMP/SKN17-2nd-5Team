{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f15688",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d81313",
   "metadata": {},
   "source": [
    "## 비지니스 목적: 이탈 고객 식별 & 방지\n",
    "### 핵심적으로 봐야 할 지표\n",
    "1. 클래스 1 Recall (이탈 고객 재현율)\n",
    "- 놓치는 이탈 고객을 최소화하기 위해 중요\n",
    "- Recall이 높을수록 실제 이탈 고객을 더 많이 잡아냄\n",
    "- 마케팅/혜택 대상 누락 방지\n",
    "\n",
    "2. 클래스 1 Precision (이탈 고객 정밀도)\n",
    "- ‘이탈 위험’으로 분류한 고객 중 실제 이탈하는 비율\n",
    "- Precision이 높으면 불필요한 혜택 비용, 자원 낭비 방지\n",
    "\n",
    "3. Balanced Accuracy\n",
    "- 클래스 0(비이탈)과 클래스 1(이탈) 성능 균형\n",
    "- 한 쪽 클래스만 잘 맞추는 모델 방지  \n",
    "\n",
    "$Balanced\\ Accuracy = \\frac{Recall_0 + Recall_1}{2}$\n",
    "\n",
    "4. ROC-AUC\n",
    "- 고객을 위험도 순서로 정렬해 상위 위험군부터 조치 가능\n",
    "- 마케팅 자원을 효율적으로 배분할 수 있음\n",
    "\n",
    "5. PR-AUC (클래스 1 기준)\n",
    "- Precision과 Recall의 관계를 종합적으로 반영\n",
    "- 실제 캠페인 효율성 평가에 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de3e8e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c4d6e5",
   "metadata": {},
   "source": [
    "## 범주형 인코딩 방법 추천표\n",
    "\n",
    "| Feature | Logistic Regression | Random Forest | XGBoost | LightGBM | SVM | 비고 |\n",
    "|---------|--------------------|--------------|---------|----------|-----|------|\n",
    "| **Home Ownership (2)** | One-Hot **(권장)** | One-Hot **(권장)** | One-Hot **(권장)** | Native Categorical **(권장)** / One-Hot **(대체 가능)** | One-Hot **(권장)** | 이진 변수이지만 회귀 계수 해석 편의를 위해 One-Hot 선호 |\n",
    "| **Ethnicity (73)** | One-Hot **(권장)** | Label Encoding **(대체 가능)** | Label Encoding **(권장)** | Native Categorical **(권장)** | One-Hot **(권장)** | 범주 수 많음 → LR/SVM은 One-Hot, 트리계열은 Label/Native |\n",
    "| **Language (38)** | One-Hot **(권장)** | Label Encoding **(대체 가능)** | Label Encoding **(권장)** | Native Categorical **(권장)** | One-Hot **(권장)** | Ethnicity와 유사하게 처리 |\n",
    "| **City (56)** | One-Hot **(권장)** | Label Encoding **(대체 가능)** | Label Encoding **(권장)** | Native Categorical **(권장)** | One-Hot **(권장)** | 도시 정보, 범주 많음 |\n",
    "| **County (4)** | One-Hot **(권장)** | One-Hot **(권장)** | One-Hot **(권장)** | Native Categorical **(권장)** | One-Hot **(권장)** | 범주 수 작음 |\n",
    "| **weekly fee (14)** | One-Hot **(권장)** | Label Encoding **(대체 가능)** | Label Encoding **(권장)** | Native Categorical **(권장)** | One-Hot **(권장)** | 금액 범위라 순서형일 수 있으나 코드상 문자열이므로 범주형 처리 |\n",
    "| **Deliveryperiod (22)** | One-Hot **(권장)** | Label Encoding **(대체 가능)** | Label Encoding **(권장)** | Native Categorical **(권장)** | One-Hot **(권장)** | 배달 패턴 정보 |\n",
    "| **Nielsen Prizm (9)** | One-Hot **(권장)** | Label Encoding **(대체 가능)** | Label Encoding **(권장)** | Native Categorical **(권장)** | One-Hot **(권장)** | 인구 통계 세그먼트 |\n",
    "| **Source Channel (50)** | One-Hot **(권장)** | Label Encoding **(대체 가능)** | Label Encoding **(권장)** | Native Categorical **(권장)** | One-Hot **(권장)** | 마케팅 채널 정보 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b062201",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d94917",
   "metadata": {},
   "source": [
    "# 1. 그냥 학습 시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb178a",
   "metadata": {},
   "source": [
    "## 인코딩\n",
    "<특이사항>\n",
    "- 한 번에 여러 컬럼을 인코딩하게 해주는 파이프라인을 제공하는 ColumnTransformer 사용 \n",
    "- LabelEncoder는 1D array 즉 특성 한 개만 인코딩 가능하기 때문에 2D array 인코딩이 가능한 OrdinalEncoder 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00dc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15438, 38)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "newspaper_df = pd.read_csv('./data/newspaper_preprocessed.csv')\n",
    "\n",
    "# dummy for Children 컬럼 drop\n",
    "newspaper_df = newspaper_df.drop('dummy for Children', axis=1)\n",
    "#display(newspaper_df.head())\n",
    "\n",
    "# 데이터 분리 (특성-타겟)\n",
    "y = newspaper_df['is_churned'].astype(int)\n",
    "X = newspaper_df.drop(columns=['is_churned'])\n",
    "\n",
    "# Random Forest 인코딩 규칙\n",
    "onehot_cols = ['Home Ownership', 'County', 'weekly fee', 'Nielsen Prizm']\n",
    "label_cols  = ['Ethnicity', 'Language', 'City', 'Deliveryperiod', 'Source Channel']\n",
    "\n",
    "# 수치형 특성\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "\n",
    "# Keep only existing columns\n",
    "onehot_cols  = [c for c in onehot_cols  if c in X.columns]\n",
    "label_cols   = [c for c in label_cols   if c in X.columns]\n",
    "numeric_cols = [c for c in numeric_cols if c in X.columns]\n",
    "\n",
    "# 인코더 & 스케일러 \n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1) \n",
    "\n",
    "# ColumnTransformer\n",
    "preprocess_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, numeric_cols),  # 수치형 → 스케일링\n",
    "        ('ohe', ohe, onehot_cols),      # One-Hot Encoding\n",
    "        ('ord', ord_enc, label_cols)    # Ordinal Encoding == multi-column label encoding\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# 전체 데이터셋 인코딩\n",
    "X_encoded= preprocess_rf.fit_transform(X)\n",
    "\n",
    "## 확인을 위해 다시 DataFrame으로 변환\n",
    "\"\"\" \n",
    "# 인코딩 된 컬럼들\n",
    "num_feats  = numeric_cols\n",
    "ohe_feats  = preprocess_rf.named_transformers_['ohe'].get_feature_names_out(onehot_cols).tolist()\n",
    "ord_feats  = label_cols\n",
    "\n",
    "encoded_cols = num_feats + ohe_feats + ord_feats\n",
    "newspaper_df = pd.DataFrame(encoded_array, columns=encoded_cols, index=X.index)\n",
    "\n",
    "# 타겟 변수 추가\n",
    "newspaper_df['is_churned'] = y.values\n",
    "\"\"\"\n",
    "print(X_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf0d57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class ratio: 0.8054 (is_churned==1 비율)\n",
      "Test  class ratio: 0.8054 (is_churned==1 비율)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "\n",
    "# Imbalance한 y값을 고려해 stratified split 진행 (클래스 비율 유지)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train class ratio:\", y_train.mean().round(4), \"(is_churned==1 비율)\")\n",
    "print(\"Test  class ratio:\", y_test.mean().round(4), \"(is_churned==1 비율)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc439c",
   "metadata": {},
   "source": [
    "학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755c8bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;clf&#x27;,\n",
       "                                        RandomForestClassifier(n_jobs=-1,\n",
       "                                                               random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;clf__class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                         &#x27;clf__max_depth&#x27;: [None, 16, 24],\n",
       "                         &#x27;clf__max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 0.5],\n",
       "                         &#x27;clf__max_samples&#x27;: [None, 0.7, 0.9],\n",
       "                         &#x27;clf__min_samples_leaf&#x27;: [1, 2, 4, 8],\n",
       "                         &#x27;clf__min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;clf__n_estimators&#x27;: [400, 800]},\n",
       "             refit=&#x27;balanced_acc&#x27;,\n",
       "             scoring={&#x27;balanced_acc&#x27;: make_scorer(balanced_accuracy_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;pr_auc_minority&#x27;: make_scorer(pr_auc_minority_scorer, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;recall_minority&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;, pos_label=0),\n",
       "                      &#x27;roc_auc&#x27;: &#x27;roc_auc&#x27;},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;clf&#x27;,\n",
       "                                        RandomForestClassifier(n_jobs=-1,\n",
       "                                                               random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;clf__class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                         &#x27;clf__max_depth&#x27;: [None, 16, 24],\n",
       "                         &#x27;clf__max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 0.5],\n",
       "                         &#x27;clf__max_samples&#x27;: [None, 0.7, 0.9],\n",
       "                         &#x27;clf__min_samples_leaf&#x27;: [1, 2, 4, 8],\n",
       "                         &#x27;clf__min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;clf__n_estimators&#x27;: [400, 800]},\n",
       "             refit=&#x27;balanced_acc&#x27;,\n",
       "             scoring={&#x27;balanced_acc&#x27;: make_scorer(balanced_accuracy_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;pr_auc_minority&#x27;: make_scorer(pr_auc_minority_scorer, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;recall_minority&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;, pos_label=0),\n",
       "                      &#x27;roc_auc&#x27;: &#x27;roc_auc&#x27;},\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;clf&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=24,\n",
       "                                        min_samples_leaf=8, n_estimators=400,\n",
       "                                        n_jobs=-1, random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=24,\n",
       "                       min_samples_leaf=8, n_estimators=400, n_jobs=-1,\n",
       "                       random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('clf',\n",
       "                                        RandomForestClassifier(n_jobs=-1,\n",
       "                                                               random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__class_weight': ['balanced'],\n",
       "                         'clf__max_depth': [None, 16, 24],\n",
       "                         'clf__max_features': ['sqrt', 'log2', 0.5],\n",
       "                         'clf__max_samples': [None, 0.7, 0.9],\n",
       "                         'clf__min_samples_leaf': [1, 2, 4, 8],\n",
       "                         'clf__min_samples_split': [2, 5, 10],\n",
       "                         'clf__n_estimators': [400, 800]},\n",
       "             refit='balanced_acc',\n",
       "             scoring={'balanced_acc': make_scorer(balanced_accuracy_score, response_method='predict'),\n",
       "                      'pr_auc_minority': make_scorer(pr_auc_minority_scorer, response_method='predict'),\n",
       "                      'recall_minority': make_scorer(recall_score, response_method='predict', pos_label=0),\n",
       "                      'roc_auc': 'roc_auc'},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "# 평가 지표\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,   # 불균형 데이터용: 클래스별 재현율 평균\n",
    "    roc_auc_score,             # 순위(랭킹) 성능\n",
    "    average_precision_score,   # PR-AUC 계산(평균정밀도)\n",
    "    recall_score,              # 재현율\n",
    "    confusion_matrix,          # 혼동 행렬\n",
    "    classification_report,     # 정밀도/재현율/F1 종합 리포트\n",
    "    make_scorer               # 커스텀 스코어러 생성\n",
    ")\n",
    "\n",
    "\n",
    "# 보조 지표: 소수 클래스(여기서는 클래스 0) PR-AUC 계산 함수\n",
    "def pr_auc_minority_scorer(y_true, y_score_pos1, **kwargs):\n",
    "    # y_score_pos1: 클래스 1(다수) 확률 → 클래스 0 지표를 위해 반전\n",
    "    return average_precision_score(1 - y_true, 1 - y_score_pos1)\n",
    "\n",
    "# 스코어링 딕셔너리\n",
    "scoring = {\n",
    "    'balanced_acc': make_scorer(balanced_accuracy_score),      # 모델 선택 기준\n",
    "    'roc_auc': 'roc_auc',                                      # 전체 순위 성능 확인\n",
    "    'recall_minority': make_scorer(recall_score, pos_label=0), # 클래스 0 재현율\n",
    "    'pr_auc_minority': make_scorer(pr_auc_minority_scorer),    # 클래스 0 PR-AUC\n",
    "}\n",
    "\n",
    "\n",
    "# 모델 & 파이프라인 \n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1, bootstrap=True)\n",
    "pipe = Pipeline([('clf', rf)])\n",
    "\n",
    "# 5) 하이퍼파라미터 검색 범위 (bootstrap=True 고정, max_samples 활용)\n",
    "#    - n_estimators: 충분한 안정성 vs 시간 균형\n",
    "#    - max_depth / min_samples_*: 과적합 제어\n",
    "#    - max_features: 전형적 선택지 + 비율 옵션\n",
    "#    - class_weight: 불균형 대응 (다수=1, 소수=0)\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [400, 800],\n",
    "    'clf__max_depth': [None, 16, 24],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4, 8],\n",
    "    'clf__max_features': ['sqrt', 'log2', 0.5],\n",
    "    'clf__class_weight': ['balanced'],\n",
    "    'clf__max_samples': [None, 0.7, 0.9],  # 부트스트랩 샘플 비율\n",
    "}\n",
    "\n",
    "# 교차검증 전략 (계층적 K-Fold)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gcv = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='balanced_acc',   # 최종 선택 기준\n",
    "    cv=cv,\n",
    "    n_jobs=-1, # cpu 코어수 극대화 (학습 속도 빠르게 하려고)\n",
    "    verbose=1 # 학습 진행 상황 설명\n",
    ")\n",
    "\n",
    "# 학습 \n",
    "gcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2b6887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 balanced_acc (CV): 0.7672\n",
      "최적 하이퍼파라미터: {'clf__class_weight': 'balanced', 'clf__max_depth': 24, 'clf__max_features': 'sqrt', 'clf__max_samples': None, 'clf__min_samples_leaf': 8, 'clf__min_samples_split': 2, 'clf__n_estimators': 400}\n",
      "\n",
      "=== 테스트 세트 성능 ===\n",
      "Balanced Acc: 0.7606\n",
      "ROC-AUC     : 0.8551\n",
      "클래스 0 Recall: 0.6889\n",
      "클래스 0 PR-AUC : 0.6023\n",
      "\n",
      "혼동 행렬:\n",
      " [[ 414  187]\n",
      " [ 417 2070]]\n",
      "\n",
      "분류 보고서:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4982    0.6889    0.5782       601\n",
      "           1     0.9171    0.8323    0.8727      2487\n",
      "\n",
      "    accuracy                         0.8044      3088\n",
      "   macro avg     0.7077    0.7606    0.7254      3088\n",
      "weighted avg     0.8356    0.8044    0.8154      3088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"최적 balanced_acc (CV):\", round(gcv.best_score_, 4))\n",
    "print(\"최적 하이퍼파라미터:\", gcv.best_params_)\n",
    "\n",
    "# 테스트 평가\n",
    "best_model = gcv.best_estimator_\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred  = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n=== 테스트 세트 성능 ===\")\n",
    "print(\"Balanced Acc:\", round(balanced_accuracy_score(y_test, y_pred), 4))\n",
    "print(\"ROC-AUC     :\", round(roc_auc_score(y_test, y_proba), 4))\n",
    "print(\"클래스 0 Recall:\", round(recall_score(y_test, y_pred, pos_label=0), 4))\n",
    "print(\"클래스 0 PR-AUC :\", round(pr_auc_minority_scorer(y_test, y_proba), 4))\n",
    "print(\"\\n혼동 행렬:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n분류 보고서:\\n\", classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f219bd5",
   "metadata": {},
   "source": [
    "### 1. Balanced Accuracy\n",
    "- **CV**: 0.7672 → 교차검증에서 평균 약 76.7%의 균형 정확도 달성  \n",
    "- **Test**: 0.7606 → 테스트 데이터에서도 약 76.1% 유지  \n",
    "\n",
    "- **의미**: 각 클래스별 Recall의 평균값  \n",
    "\n",
    "- **이 데이터에서 중요한 이유**  \n",
    "    - `is_churned`가 80:20 불균형 분포  \n",
    "    - 단순 Accuracy는 다수 클래스(80%) 예측에 치우쳐도 높게 나올 수 있음  \n",
    "    - Balanced Accuracy는 두 클래스의 성능을 동일 비중으로 평가  \n",
    "\n",
    "\n",
    "### 2. ROC-AUC (0.8551)\n",
    "- **의미**: 임계값과 상관없이, 모델이 양성 클래스(이탈 고객) 점수를 음성 클래스(비이탈)보다 높게 매기는 비율  \n",
    "- 1.0이면 완벽 구분, 0.5면 무작위 예측 수준  \n",
    "- **장점**: 분류 기준(threshold)을 정하기 전, **모델의 순위 매김(ranking) 능력**을 평가 가능  \n",
    "\n",
    "\n",
    "### 3. Recall (클래스 0 = 비이탈 고객)\n",
    "- **값**: 0.6889 → 실제 비이탈 고객 중 약 68.9%를 올바르게 예측  \n",
    "- **해석**:  \n",
    "    - 클래스 0이 소수 클래스이므로, **소수 클래스의 재현율** 확인은 모델 공정성 평가에 중요  \n",
    "    - **Precision이 0.50 수준** → “비이탈”로 예측된 고객 중 절반은 실제 이탈 고객 → 잘못된 안심 효과 가능성 있음  \n",
    "    - 비즈니스 목표가 “이탈 방지”라면, **클래스 1(이탈)** Recall과 함께 해석 필요  \n",
    "\n",
    "\n",
    "### 4. Recall (클래스 1 = 이탈 고객)\n",
    "- **값**: 0.8323 → 실제 이탈 고객의 약 83.2%를 올바르게 예측  \n",
    "- **해석**:  \n",
    "    - Precision이 0.92로 매우 높음 → \"이탈\"로 분류된 고객 대부분이 실제 이탈 고객  \n",
    "    - 놓치는 이탈 고객(FN)이 16.8% 존재 → 이 비율을 낮추면 이탈 방지 효과 상승  \n",
    "\n",
    "\n",
    "### 5. PR-AUC (클래스 0, 0.6023)\n",
    "- **의미**: Precision-Recall 곡선 아래 면적  \n",
    "- **이유**:  \n",
    "    - **불균형 데이터**에서는 ROC-AUC보다 PR-AUC가 실제 성능을 더 현실적으로 반영  \n",
    "    - 0.60 수준은 “보통” 정도이며, 소수 클래스 예측의 Precision·Recall 모두 개선 여지 있음  \n",
    "\n",
    "\n",
    "### 6. 혼동 행렬 해석\n",
    "- **TN (414)**: 비이탈을 정확히 예측  \n",
    "- **FP (187)**: 비이탈인데 이탈로 잘못 예측 → 불필요한 유지 마케팅 발생 가능  \n",
    "- **FN (417)**: 이탈인데 비이탈로 잘못 예측 → **이탈 방지 실패로 직결**  \n",
    "- **TP (2070)**: 이탈을 정확히 예측 → 방지 캠페인 타겟 가능  \n",
    "\n",
    "\n",
    "### <종합 해석>\n",
    "- **이탈 고객(클래스 1)**: Precision 92%, Recall 83%로 매우 우수  \n",
    "- **비이탈 고객(클래스 0)**: Precision이 낮아(50%) 오분류 리스크 존재  \n",
    "    - = 비이탈 고객이 정말 잔류를 할지에 대한 예측력이 떨어짐  \n",
    "    - **이를 보완하기 위해서 oversampling(SMOTENC 등)을 진행할 당위성이 충분히 존재**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c26febd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321f71f9",
   "metadata": {},
   "source": [
    "# 2. 학습 시 Oversampling 적용\n",
    "<SMOTENC (=범주형 데이터를 포함한 SMOTE) 기법을 이용>\n",
    "\n",
    "-현재 데이터에서 is_churned=0의 비율이 매우 적어 이를 보완하기 위해 SMOTENC와 같은 오버샘플링 기법을 적용하려고 함. \n",
    "\n",
    "- 이때 중요한 점은 교차검증(CV) 환경에서는 반드시 SMOTENC를 파이프라인(Pipeline)에 포함하는 것이 좋다는 것. \n",
    "\n",
    "- 그 이유는 첫째, 데이터 누수를 방지하기 위함. 전체 데이터에서 한 번 오버샘플링을 하고 이를 폴드별로 나누면, 각 폴드가 동일한 합성 데이터를 공유하게 되어 검증 점수가 실제보다 높게 나오는 문제가 발생. \n",
    "    - 파이프라인에 포함하면 각 폴드의 훈련 데이터에만 SMOTENC를 적용하여 매번 새로운 합성 데이터를 만들기 때문에 이러한 누수를 방지할 수 있음. \n",
    "\n",
    "    - 둘째, 오버샘플링 방식과 모델 하이퍼파라미터를 동시에 최적화할 수 있습니다. SMOTENC 자체도 k_neighbors나 sampling_strategy 등 성능에 영향을 주는 하이퍼파라미터를 가지므로, 파이프라인으로 묶어 그리드서치 시 함께 탐색하는 것이 효과적. \n",
    "\n",
    "    - 마지막으로, 코드의 재현성과 간결성을 높히기 가능. 파이프라인을 사용하면 모델 학습 과정이 명확해져 팀원들이 동일한 절차를 손쉽게 재현할 수 있습니다.\n",
    "\n",
    "- 단, 교차검증을 사용하지 않고 단일 train/valid 분할만으로 실험하는 경우에는, 훈련 세트에서만 오버샘플링을 한 뒤 모델을 학습하고 원래 테스트 세트로 평가하는 절차를 따르더라도 무방하지만 CV와 하이퍼파라미터 튜닝을 함께 진행한다면 파이프라인 사용이 사실상 필수라고 보아야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97ed701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef18e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1cfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 balanced_acc (CV): 0.7549\n",
      "최적 하이퍼파라미터: {'clf__class_weight': None, 'clf__max_depth': 16, 'clf__max_features': 'sqrt', 'clf__max_samples': None, 'clf__min_samples_leaf': 12, 'clf__min_samples_split': 2, 'clf__n_estimators': 600, 'smote__k_neighbors': 3, 'smote__sampling_strategy': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "X_raw = X\n",
    "\n",
    "# SMOTENC & ColumnTransformer에서 쓸 \"컬럼 인덱스\"\n",
    "onehot_idx  = [X_raw.columns.get_loc(c) for c in onehot_cols]\n",
    "label_idx   = [X_raw.columns.get_loc(c) for c in label_cols]\n",
    "numeric_idx = [X_raw.columns.get_loc(c) for c in numeric_cols]\n",
    "\n",
    "# SMOTENC에 전달할 '범주형' 컬럼 인덱스 (OHE 대상 + Ordinal 대상)\n",
    "#categorical_idx_for_smote = np.array(onehot_idx + label_idx, dtype=int)\n",
    "categorical_idx_for_smote = list(onehot_idx + label_idx)\n",
    "\n",
    "# SMOTENC 정의\n",
    "smote = SMOTENC(\n",
    "    categorical_features=categorical_idx_for_smote,\n",
    "    sampling_strategy='auto',    # 소수 클래스를 다수에 가깝게\n",
    "    k_neighbors=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# train/test 분리\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_idx),  # 수치형 → 스케일링\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False), onehot_idx),\n",
    "        ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), label_idx),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=1, bootstrap=True)\n",
    "\n",
    "\n",
    "# 6) SMOTENC(원본) → 전처리(인코딩) → RF\n",
    "pipe = ImbPipeline(steps=[\n",
    "    ('smote', smote),\n",
    "    ('prep', preprocess),\n",
    "    ('clf', rf),\n",
    "])\n",
    "\n",
    "\n",
    "# 스코어러 설정 (소수 클래스=0 기준 PR-AUC 포함)\n",
    "def pr_auc_minority(y_true, y_score_pos1, **kwargs):\n",
    "    # average_precision_score는 \"양성=1\" 기준 → 0 기준으로 보려면 반전\n",
    "    return average_precision_score(1 - y_true, 1 - y_score_pos1)\n",
    "\n",
    "scoring = {\n",
    "    'balanced_acc': make_scorer(balanced_accuracy_score),\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'recall_minority': make_scorer(recall_score, pos_label=0),\n",
    "    'pr_auc_minority': make_scorer(pr_auc_minority, needs_proba=True),\n",
    "}\n",
    "\n",
    "# 하이퍼파라미터 그리드 (이전 최적값 주변 + SMOTENC 동시 탐색)\n",
    "param_grid = {\n",
    "    # RF: 이전 최적 근처를 촘촘히 재탐색\n",
    "    'clf__n_estimators': [600, 800],\n",
    "    'clf__max_depth': [16, 24],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [4, 8, 12],        # 합성 노이즈 완충을 위해 약간 키움\n",
    "    'clf__max_features': ['sqrt'],\n",
    "    'clf__class_weight': [None],    # 오버샘플링과의 조합 비교\n",
    "    'clf__max_samples': [None, 0.9],\n",
    "\n",
    "    # SMOTENC: 데이터 밀도에 민감 → 함께 튜닝 권장\n",
    "    'smote__k_neighbors': [3, 5],\n",
    "    'smote__sampling_strategy': ['auto', 0.5],  # 소수 클래스 비율(0.5=40%)\n",
    "}\n",
    "\n",
    "# 교차검증 & 그리드서치\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "gcv = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='balanced_acc',     # 최종 선택 기준(두 클래스 균형 성능)\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    pre_dispatch='2*n_jobs',  # RAM 초과 억제\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "# 학습\n",
    "gcv.fit(X_train_raw, y_train)\n",
    "\n",
    "print(\"최적 balanced_acc (CV):\", round(gcv.best_score_, 4))\n",
    "print(\"최적 하이퍼파라미터:\", gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7092ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 테스트 성능 (SMOTENC 포함) ===\n",
      "Balanced Acc: 0.7606\n",
      "ROC-AUC     : 0.8393\n",
      "클래스 0 Recall: 0.7121\n",
      "클래스 0 PR-AUC : 0.574\n",
      "\n",
      "혼동 행렬:\n",
      " [[ 428  173]\n",
      " [ 475 2012]]\n",
      "\n",
      "분류 보고서:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4740    0.7121    0.5691       601\n",
      "           1     0.9208    0.8090    0.8613      2487\n",
      "\n",
      "    accuracy                         0.7902      3088\n",
      "   macro avg     0.6974    0.7606    0.7152      3088\n",
      "weighted avg     0.8339    0.7902    0.8044      3088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가 (원본 테스트셋: 여기에서는 클래스 불균형이 그대로 남아있음)\n",
    "best_model = gcv.best_estimator_\n",
    "y_proba = best_model.predict_proba(X_test_raw)[:, 1]\n",
    "y_pred  = best_model.predict(X_test_raw)\n",
    "\n",
    "print(\"\\n=== 테스트 성능 (SMOTENC 포함) ===\")\n",
    "print(\"Balanced Acc:\", round(balanced_accuracy_score(y_test, y_pred), 4))\n",
    "print(\"ROC-AUC     :\", round(roc_auc_score(y_test, y_proba), 4))\n",
    "print(\"클래스 0 Recall:\", round(recall_score(y_test, y_pred, pos_label=0), 4))\n",
    "print(\"클래스 0 PR-AUC :\", round(pr_auc_minority(y_test, y_proba), 4))\n",
    "print(\"\\n혼동 행렬:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n분류 보고서:\\n\", classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72443a2",
   "metadata": {},
   "source": [
    "메모리 누수가 발생했으므로 정확한 학습 및 평가가 이루어졌다고 보기 힘듬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd14b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dcdc58",
   "metadata": {},
   "source": [
    "# 3. RAM 누수 억제 학습\n",
    "- 하이퍼파라미터 조정\n",
    "- k-fold k=3으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d746f645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n",
      "최적 balanced_acc (CV): 0.7528\n",
      "최적 하이퍼파라미터: {'clf__class_weight': None, 'clf__max_depth': 16, 'clf__max_features': 'sqrt', 'clf__max_samples': None, 'clf__min_samples_leaf': 8, 'clf__min_samples_split': 2, 'clf__n_estimators': 600, 'smote__k_neighbors': 3, 'smote__sampling_strategy': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 그리드 (이전 최적값 주변 + SMOTENC 동시 탐색)\n",
    "param_grid = {\n",
    "    # RF: 이전 최적 근처를 촘촘히 재탐색\n",
    "    'clf__n_estimators': [600, 800],\n",
    "    'clf__max_depth': [16, 24],\n",
    "    'clf__min_samples_split': [2, 5],\n",
    "    'clf__min_samples_leaf': [8, 12],        # 합성 노이즈 완충을 위해 약간 키움\n",
    "    'clf__max_features': ['sqrt'],\n",
    "    'clf__class_weight': [None],    # 오버샘플링과의 조합 비교\n",
    "    'clf__max_samples': [None, 0.9],\n",
    "\n",
    "    # SMOTENC: 데이터 밀도에 민감 → 함께 튜닝 권장\n",
    "    'smote__k_neighbors': [3, 5],\n",
    "    'smote__sampling_strategy': ['auto', 0.5],  # 소수 클래스 비율(0.5=40%)\n",
    "}\n",
    "\n",
    "# 교차검증 & 그리드서치\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "gcv = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='balanced_acc',     # 최종 선택 기준(두 클래스 균형 성능)\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    pre_dispatch='2*n_jobs',  # RAM 초과 억제\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "# 학습\n",
    "gcv.fit(X_train_raw, y_train)\n",
    "\n",
    "print(\"최적 balanced_acc (CV):\", round(gcv.best_score_, 4))\n",
    "print(\"최적 하이퍼파라미터:\", gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66163894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 테스트 성능 (SMOTENC 포함) ===\n",
      "Balanced Acc: 0.7634\n",
      "ROC-AUC     : 0.84\n",
      "클래스 0 Recall: 0.7138\n",
      "클래스 0 PR-AUC : 0.5759\n",
      "\n",
      "혼동 행렬:\n",
      " [[ 429  172]\n",
      " [ 465 2022]]\n",
      "\n",
      "분류 보고서:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4799    0.7138    0.5739       601\n",
      "           1     0.9216    0.8130    0.8639      2487\n",
      "\n",
      "    accuracy                         0.7937      3088\n",
      "   macro avg     0.7007    0.7634    0.7189      3088\n",
      "weighted avg     0.8356    0.7937    0.8075      3088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가 (원본 테스트셋: 여기에서는 클래스 불균형이 그대로 남아있음)\n",
    "best_model = gcv.best_estimator_\n",
    "y_proba = best_model.predict_proba(X_test_raw)[:, 1]\n",
    "y_pred  = best_model.predict(X_test_raw)\n",
    "\n",
    "print(\"\\n=== 테스트 성능 (SMOTENC 포함) ===\")\n",
    "print(\"Balanced Acc:\", round(balanced_accuracy_score(y_test, y_pred), 4))\n",
    "print(\"ROC-AUC     :\", round(roc_auc_score(y_test, y_proba), 4))\n",
    "print(\"클래스 0 Recall:\", round(recall_score(y_test, y_pred, pos_label=0), 4))\n",
    "print(\"클래스 0 PR-AUC :\", round(pr_auc_minority(y_test, y_proba), 4))\n",
    "print(\"\\n혼동 행렬:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n분류 보고서:\\n\", classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901772f7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98739c4",
   "metadata": {},
   "source": [
    "# 4. Treshold 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef336dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Best threshold for Recall>=0.90: 0.3765\n",
      "🔹 Best threshold for max F2-score: 0.0903\n",
      "\n",
      "===== Recall≥0.90 (Threshold=0.3765) =====\n",
      "Confusion Matrix:\n",
      "[[ 306  295]\n",
      " [ 248 2239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5523    0.5092    0.5299       601\n",
      "           1     0.8836    0.9003    0.8919      2487\n",
      "\n",
      "    accuracy                         0.8242      3088\n",
      "   macro avg     0.7180    0.7047    0.7109      3088\n",
      "weighted avg     0.8191    0.8242    0.8214      3088\n",
      "\n",
      "\n",
      "===== Max F2 (Threshold=0.0903) =====\n",
      "Confusion Matrix:\n",
      "[[  68  533]\n",
      " [  11 2476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8608    0.1131    0.2000       601\n",
      "           1     0.8229    0.9956    0.9010      2487\n",
      "\n",
      "    accuracy                         0.8238      3088\n",
      "   macro avg     0.8418    0.5544    0.5505      3088\n",
      "weighted avg     0.8302    0.8238    0.7646      3088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, fbeta_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1. 테스트 세트에서 Class 1 확률값 예측\n",
    "y_proba = gcv.best_estimator_.predict_proba(X_test_raw)[:, 1]  # Class 1 확률\n",
    "\n",
    "# 2. Precision-Recall Curve 계산\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# 3. F2-score 계산 (Recall 가중치 ↑)\n",
    "f2_scores = []\n",
    "for t in thresholds:\n",
    "    preds = (y_proba >= t).astype(int)\n",
    "    f2_scores.append(fbeta_score(y_test, preds, beta=2))\n",
    "\n",
    "f2_scores = np.array(f2_scores)\n",
    "\n",
    "# 4. 두 가지 기준 찾기\n",
    "# (1) Recall >= 0.90 중에서 precision 최대인 threshold\n",
    "target_recall_idx = np.where(recalls >= 0.90)[0]\n",
    "if len(target_recall_idx) > 0:\n",
    "    best_idx_recall = target_recall_idx[np.argmax(precisions[target_recall_idx])]\n",
    "    best_threshold_recall = thresholds[best_idx_recall]\n",
    "else:\n",
    "    best_threshold_recall = None\n",
    "\n",
    "# (2) F2-score 최대 threshold\n",
    "best_idx_f2 = np.argmax(f2_scores)\n",
    "best_threshold_f2 = thresholds[best_idx_f2]\n",
    "\n",
    "print(f\"🔹 Best threshold for Recall>=0.90: {best_threshold_recall:.4f}\" if best_threshold_recall else \"No threshold meets Recall>=0.90\")\n",
    "print(f\"🔹 Best threshold for max F2-score: {best_threshold_f2:.4f}\")\n",
    "\n",
    "# 5. 각 threshold에서 성능 비교\n",
    "for th, name in [(best_threshold_recall, \"Recall≥0.90\"), (best_threshold_f2, \"Max F2\")]:\n",
    "    if th is not None:\n",
    "        preds = (y_proba >= th).astype(int)\n",
    "        print(f\"\\n===== {name} (Threshold={th:.4f}) =====\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, preds))\n",
    "        print(classification_report(y_test, preds, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff39462",
   "metadata": {},
   "source": [
    "# 현재까지 결과:\n",
    "## 1. 성능 비교\n",
    "\n",
    "| 모델 | Balanced Acc | ROC-AUC | Class 0 Recall | Class 0 Precision | Class 1 Recall | Class 1 Precision | 특징 |\n",
    "|------|-------------|---------|----------------|-------------------|----------------|-------------------|------|\n",
    "| **SMOTENC X** | 0.7606 | **0.8551** | 0.6889 | **0.4982** | 0.8323 | 0.9171 | 기본 모델 |\n",
    "| **SMOTENC O (모델1)** | 0.7606 | 0.8393 | 0.7121 | 0.4740 | 0.8090 | **0.9208** | 메모리 경고 발생 |\n",
    "| **SMOTENC O (모델2)** | **0.7634** | 0.8400 | **0.7138** | 0.4799 | 0.8130 | **0.9216** | 튜닝 안정 |\n",
    "| **Threshold 튜닝 (Recall ≥ 0.90)** | 0.7047 | N/A | 0.5092 | 0.5523 | **0.9003** | 0.8836 | FN 대폭 감소 |\n",
    "| **Threshold 튜닝 (Max F2)** | **0.5544** | N/A | **0.1131** | **0.8608** | **0.9956** | 0.8229 | 이탈 거의 100% 탐지 |\n",
    "\n",
    "\n",
    "## 2. 해석\n",
    "\n",
    "- **목표: 이탈 고객 탐지 (is_churned=1)**  \n",
    "  - **Recall ≥ 0.90 모델** → Class 1 Recall 90% 달성, FN 크게 줄임. Precision도 0.88로 나쁘지 않음.  \n",
    "  - **Max F2 모델** → Class 1 Recall 99.6% 달성, 거의 모든 이탈 고객 잡음. 대신 Class 0 Recall이 매우 낮음(잔류 고객 오분류 많음).\n",
    "- **ROC-AUC & 전반적인 확률 예측력**  \n",
    "  - SMOTENC 미적용 모델이 가장 높음 (0.8551) → 전체 예측 정확도/순위 기반 평가는 여전히 우위.\n",
    "- **균형 성능**  \n",
    "  - Balanced Accuracy는 SMOTENC 모델들이 약간 높지만, threshold 튜닝 모델들은 Class 0 성능이 희생되며 하락.\n",
    "\n",
    "\n",
    "\n",
    "## 3. 추천\n",
    "- **이탈 고객을 놓치면 안 되는 경우**  \n",
    "  - **Max F2 모델**이 최적 → Recall 99.6%, 거의 모든 이탈 포착  \n",
    "  - 단, 정상 고객을 많이 이탈로 예측하므로, 후속 필터링(비용 고려)이 필요\n",
    "- **이탈 고객을 많이 잡으면서도 Precision 유지**  \n",
    "  - **Recall ≥ 0.90 모델**이 현실적 → Recall 90%, Precision 88%\n",
    "- **균형된 성능 & 안정적인 모델**  \n",
    "  - SMOTENC 미적용 모델 + Threshold 튜닝이 안전한 선택\n",
    "\n",
    "\n",
    "## 정리:\n",
    "- SMOTENC를 적용하는 것이 오히려 약간의 성능 저하가 일어남\n",
    "    - class_weight='balanced'가 클래스 불균형 문제를 자동으로 보정해 주어서 SMOTENC로 인한 추가 이득이 거의 없는 것으로 추정\n",
    "    - 동시에 쓰면 효과가 중첩되어 과한 보정이 일어날 수 있고, 그게 성능 하락 원인 중 하나로 보입\n",
    "- **Recall ≥ 0.90 모델** → 가장 비즈니스적으로 안정적  \n",
    "- **Max F2 모델** → 캠페인 비용 제한이 없을 때 추천  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449d100",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32a1321",
   "metadata": {},
   "source": [
    "# 5. SMOTENC 미적용 + RandomForest 튜닝 + 임계값(Threshold) 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5d4c970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: (15438, 38)\n",
      "Train class ratio (is_churned==1): 0.8054\n",
      "Test  class ratio (is_churned==1): 0.8054\n",
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
      "\n",
      "[GridSearchCV 결과]\n",
      "최적 balanced_acc (CV): 0.7672\n",
      "최적 하이퍼파라미터: {'clf__class_weight': 'balanced', 'clf__max_depth': 24, 'clf__max_features': 'sqrt', 'clf__max_samples': None, 'clf__min_samples_leaf': 8, 'clf__min_samples_split': 2, 'clf__n_estimators': 400}\n",
      "\n",
      "=== [테스트] 기본 임계값 0.5 ===\n",
      "Balanced Acc: 0.7606\n",
      "ROC-AUC     : 0.8551\n",
      "Class 0 Recall: 0.6889\n",
      "Class 0 PR-AUC: 0.6023\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 414  187]\n",
      " [ 417 2070]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4982    0.6889    0.5782       601\n",
      "           1     0.9171    0.8323    0.8727      2487\n",
      "\n",
      "    accuracy                         0.8044      3088\n",
      "   macro avg     0.7077    0.7606    0.7254      3088\n",
      "weighted avg     0.8356    0.8044    0.8154      3088\n",
      "\n",
      "\n",
      "[VAL] 목표 Recall≥0.90 임계값: 0.4753\n",
      "[VAL] F2 최대 임계값: 0.2652\n",
      "\n",
      "=== [테스트] Recall≥0.90 (Threshold=0.4753) ===\n",
      "Class 1 Precision: 0.9116\n",
      "Class 1 Recall   : 0.8536\n",
      "Balanced Acc     : 0.7554\n",
      "ROC-AUC (unchanged): 0.8551\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 395  206]\n",
      " [ 364 2123]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5204    0.6572    0.5809       601\n",
      "           1     0.9116    0.8536    0.8816      2487\n",
      "\n",
      "    accuracy                         0.8154      3088\n",
      "   macro avg     0.7160    0.7554    0.7313      3088\n",
      "weighted avg     0.8354    0.8154    0.8231      3088\n",
      "\n",
      "\n",
      "=== [테스트] Max F2 (Threshold=0.2652) ===\n",
      "Class 1 Precision: 0.8492\n",
      "Class 1 Recall   : 0.9739\n",
      "Balanced Acc     : 0.6292\n",
      "ROC-AUC (unchanged): 0.8551\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 171  430]\n",
      " [  65 2422]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7246    0.2845    0.4086       601\n",
      "           1     0.8492    0.9739    0.9073      2487\n",
      "\n",
      "    accuracy                         0.8397      3088\n",
      "   macro avg     0.7869    0.6292    0.6579      3088\n",
      "weighted avg     0.8250    0.8397    0.8102      3088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 전체 과정 재구현\n",
    "\n",
    "# 1) 라이브러리 & 데이터 로드\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,   # 불균형 데이터용: 클래스별 재현율 평균\n",
    "    roc_auc_score,             # 순위(랭킹) 성능\n",
    "    average_precision_score,   # PR-AUC 계산(평균정밀도)\n",
    "    recall_score,              # 재현율\n",
    "    confusion_matrix,          # 혼동 행렬\n",
    "    classification_report,     # 정밀도/재현율/F1 종합 리포트\n",
    "    make_scorer,               # 커스텀 스코어러\n",
    "    precision_recall_curve,    # 임계값 튜닝용 PR-커브\n",
    "    fbeta_score,               # F-베타 점수\n",
    "    precision_score, precision_recall_curve\n",
    ")\n",
    "\n",
    "# 데이터 로드\n",
    "newspaper_df = pd.read_csv('./data/newspaper_preprocessed.csv')\n",
    "\n",
    "# =========================\n",
    "# 2) 전처리: 인코딩 스키마\n",
    "# =========================\n",
    "# (참고) 'dummy for Children'는 타겟/인코딩 혼선 방지를 위해 제거\n",
    "if 'dummy for Children' in newspaper_df.columns:\n",
    "    newspaper_df = newspaper_df.drop('dummy for Children', axis=1)\n",
    "\n",
    "# 타겟/피처 분리\n",
    "y = newspaper_df['is_churned'].astype(int)\n",
    "X = newspaper_df.drop(columns=['is_churned'])\n",
    "\n",
    "# 범주형: One-Hot / Ordinal 대상 지정 (RandomForest 기준)\n",
    "onehot_cols = ['Home Ownership', 'County', 'weekly fee', 'Nielsen Prizm']\n",
    "label_cols  = ['Ethnicity', 'Language', 'City', 'Deliveryperiod', 'Source Channel']\n",
    "\n",
    "# 수치형 컬럼 자동 탐지\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "\n",
    "# 실제 존재하는 컬럼만 사용 (방어코드)\n",
    "onehot_cols  = [c for c in onehot_cols  if c in X.columns]\n",
    "label_cols   = [c for c in label_cols   if c in X.columns]\n",
    "numeric_cols = [c for c in numeric_cols if c in X.columns]\n",
    "\n",
    "# 인코더 & 스케일러\n",
    "scaler  = StandardScaler()\n",
    "ohe     = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1) \n",
    "\n",
    "# 열별 전처리기\n",
    "preprocess_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, numeric_cols),  # 수치형 → 스케일링\n",
    "        ('ohe', ohe, onehot_cols),      # 명목형 → One-Hot\n",
    "        ('ord', ord_enc, label_cols)    # 고카디널리티 → Ordinal(라벨 인코딩 대체)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# 전체 데이터 인코딩\n",
    "X_encoded = preprocess_rf.fit_transform(X)\n",
    "print(\"Encoded shape:\", X_encoded.shape)\n",
    "\n",
    "\n",
    "# 3) 학습/평가용 분리\n",
    "# (중요) 불균형 대응을 위해 stratify 사용\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "print(\"Train class ratio (is_churned==1):\", y_train.mean().round(4))\n",
    "print(\"Test  class ratio (is_churned==1):\", y_test.mean().round(4))\n",
    "\n",
    "\n",
    "# 4) 평가 스코어러 구성\n",
    "# 클래스 0(PR-AUC) 보조 지표 (필요 시)\n",
    "def pr_auc_minority_scorer(y_true, y_score_pos1, **kwargs):\n",
    "    # y_score_pos1: 클래스 1 확률 → 클래스 0 기준으로 보려면 반전\n",
    "    return average_precision_score(1 - y_true, 1 - y_score_pos1)\n",
    "\n",
    "scoring = {\n",
    "    'balanced_acc': make_scorer(balanced_accuracy_score),      # 모델 선택 기준\n",
    "    'roc_auc': 'roc_auc',                                      # 전체 랭킹 성능\n",
    "    'recall_minority': make_scorer(recall_score, pos_label=0), # 클래스 0 재현율\n",
    "    'pr_auc_minority': make_scorer(pr_auc_minority_scorer),    # 클래스 0 PR-AUC\n",
    "}\n",
    "\n",
    "\n",
    "# 5) RandomForest + GridSearchCV\n",
    "# (안정성) 중첩 병렬 과도 방지를 위해 RF는 n_jobs=1, GridSearchCV에서 병렬화 (-1)\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=1, bootstrap=True)\n",
    "pipe = Pipeline([('clf', rf)])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [400, 800],\n",
    "    'clf__max_depth': [None, 16, 24],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4, 8],\n",
    "    'clf__max_features': ['sqrt', 'log2', 0.5],\n",
    "    'clf__class_weight': ['balanced'],\n",
    "    'clf__max_samples': [None, 0.7, 0.9],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gcv = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='balanced_acc',  # 최종 선택 기준\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    pre_dispatch='2*n_jobs'\n",
    ")\n",
    "\n",
    "gcv.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n[GridSearchCV 결과]\")\n",
    "print(\"최적 balanced_acc (CV):\", round(gcv.best_score_, 4))\n",
    "print(\"최적 하이퍼파라미터:\", gcv.best_params_)\n",
    "\n",
    "# 6) 기본 임계값(0.5) 테스트 성능\n",
    "best_model = gcv.best_estimator_\n",
    "y_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_test  = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n=== [테스트] 기본 임계값 0.5 ===\")\n",
    "print(\"Balanced Acc:\", round(balanced_accuracy_score(y_test, y_pred_test), 4))\n",
    "print(\"ROC-AUC     :\", round(roc_auc_score(y_test, y_proba_test), 4))\n",
    "print(\"Class 0 Recall:\", round(recall_score(y_test, y_pred_test, pos_label=0), 4))\n",
    "print(\"Class 0 PR-AUC:\", round(pr_auc_minority_scorer(y_test, y_proba_test), 4))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test, digits=4))\n",
    "\n",
    "\n",
    "# 7) 임계값 튜닝 (양성=클래스 1: 이탈 고객)\n",
    "# 7-1) 훈련 세트 내부에서 검증 세트 분리 (누수 방지용 권장 절차)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "# (선택) 엄밀히 하려면: 최적 하이퍼파라미터로 새 모델 생성 후 X_tr로 재학습\n",
    "# 여기서는 이미 gcv.best_estimator_가 X_train 전체로 학습되어 있으므로 그대로 사용\n",
    "# best_model.fit(X_tr, y_tr)  # 엄밀 재학습을 원하면 주석 해제\n",
    "\n",
    "# 7-2) 검증 세트에서 PR-커브로 임계값 후보 탐색\n",
    "val_proba_cls1 = best_model.predict_proba(X_val)[:, 1]\n",
    "prec_arr, rec_arr, thr_arr = precision_recall_curve(y_val, val_proba_cls1)\n",
    "\n",
    "# (A) 목표 Recall(예: 0.90) 이상 중 Precision 최대 임계값\n",
    "target_recall = 0.90\n",
    "candidates_idx = np.where(rec_arr[:-1] >= target_recall)[0]\n",
    "if len(candidates_idx) > 0:\n",
    "    best_idx_recall = candidates_idx[np.argmax(prec_arr[candidates_idx])]\n",
    "    thr_recall = thr_arr[best_idx_recall]\n",
    "else:\n",
    "    thr_recall = 0.5  # 후보가 없으면 기본값 유지\n",
    "\n",
    "# (B) F2 점수(Recall 가중↑) 최대 임계값\n",
    "f2_scores = []\n",
    "for t in thr_arr:\n",
    "    preds_val = (val_proba_cls1 >= t).astype(int)\n",
    "    f2_scores.append(fbeta_score(y_val, preds_val, beta=2))\n",
    "f2_scores = np.array(f2_scores)\n",
    "best_idx_f2 = np.argmax(f2_scores[:-1])  # 마지막 포인트 제외\n",
    "thr_f2 = thr_arr[best_idx_f2]\n",
    "\n",
    "print(f\"\\n[VAL] 목표 Recall≥{target_recall:.2f} 임계값: {thr_recall:.4f}\")\n",
    "print(f\"[VAL] F2 최대 임계값: {thr_f2:.4f}\")\n",
    "\n",
    "\n",
    "# 8) 테스트 세트에서 임계값 적용 평가\n",
    "def eval_with_threshold(y_true, proba_cls1, thr, tag=\"\"):\n",
    "    y_pred_thr = (proba_cls1 >= thr).astype(int)\n",
    "    print(f\"\\n=== [테스트] {tag} (Threshold={thr:.4f}) ===\")\n",
    "    print(\"Class 1 Precision:\", round(precision_score(y_true, y_pred_thr, pos_label=1), 4))\n",
    "    print(\"Class 1 Recall   :\", round(recall_score(y_true, y_pred_thr, pos_label=1), 4))\n",
    "    print(\"Balanced Acc     :\", round(balanced_accuracy_score(y_true, y_pred_thr), 4))\n",
    "    print(\"ROC-AUC (unchanged):\", round(roc_auc_score(y_true, proba_cls1), 4))  # ROC-AUC는 임계값 무관\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true, y_pred_thr))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred_thr, digits=4))\n",
    "\n",
    "proba_test_cls1 = best_model.predict_proba(X_test)[:, 1]\n",
    "eval_with_threshold(y_test, proba_test_cls1, thr_recall, tag=f\"Recall≥{target_recall:.2f}\")\n",
    "eval_with_threshold(y_test, proba_test_cls1, thr_f2,     tag=\"Max F2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4fa91",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f31be",
   "metadata": {},
   "source": [
    "| 모델 | SMOTENC | Balanced Acc | ROC-AUC | Class 0 Recall | Class 0 Precision | Class 1 Recall | Class 1 Precision | 특징 |\n",
    "|------|---------|-------------|---------|----------------|-------------------|----------------|-------------------|------|\n",
    "| **기본 모델** | X | 0.7606 | **0.8551** | 0.6889 | **0.4982** | 0.8323 | 0.9171 | 기본 세팅, 두 클래스 균형 양호 |\n",
    "| **SMOTENC 적용 (모델1)** | O | 0.7606 | 0.8393 | 0.7121 | 0.4740 | 0.8090 | **0.9208** | 메모리 경고 발생 |\n",
    "| **SMOTENC 적용 (모델2)** | O | **0.7634** | 0.8400 | **0.7138** | 0.4799 | 0.8130 | **0.9216** | SMOTENC + 안정 튜닝 |\n",
    "| **Threshold 튜닝 (Recall ≥ 0.90)** | X | 0.7554 | **0.8551** | 0.6572 | 0.5204 | **0.8536** | 0.9116 | FN 감소, Precision 유지 |\n",
    "| **Threshold 튜닝 (Max F2)** | X | **0.6292** | **0.8551** | **0.2845** | **0.7246** | **0.9739** | 0.8492 | 이탈 탐지 극대화, 정상 고객 오탐 증가 |\n",
    "| **Threshold 튜닝 (Recall ≥ 0.90)** | O | 0.7047 | N/A | 0.5092 | 0.5523 | **0.9003** | 0.8836 | FN 대폭 감소, Precision 소폭 하락 |\n",
    "| **Threshold 튜닝 (Max F2)** | O | **0.5544** | N/A | **0.1131** | **0.8608** | **0.9956** | 0.8229 | 거의 모든 이탈 탐지, 정상 고객 오탐 매우 많음 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ba7b4",
   "metadata": {},
   "source": [
    "## 📊 모델 비교 및 추천\n",
    "\n",
    "### 1. 해석 기준\n",
    "- **프로젝트 목표**: 이탈 고객(`is_churned == 1`)을 최대한 놓치지 않는 것 (Recall↑),  \n",
    "  그러나 **정상 고객을 너무 많이 오탐**하면 비용 증가 → Precision도 고려 필요.\n",
    "- **Balanced Accuracy**: 두 클래스 재현율 평균. 데이터 불균형 시 유용.\n",
    "- **ROC-AUC**: 분류 전체 성능.  \n",
    "- **Threshold 튜닝**: Recall과 Precision의 균형을 의도적으로 조정.\n",
    "\n",
    "### 2. 핵심 비교\n",
    "| 후보 | 장점 | 단점 | 종합 평가 |\n",
    "|------|------|------|-----------|\n",
    "| **기본 모델 (SMOTENC X)** | 높은 ROC-AUC (0.8551), 균형 잡힌 성능, Class 1 Recall 0.8323 | Class 0 Recall 0.6889 → 정상 고객 탐지 조금 부족 | 안정적이고 해석 쉬움 |\n",
    "| **SMOTENC 적용 (모델2)** | Balanced Acc 최고 (0.7634), Class 0 Recall 0.7138 | ROC-AUC가 기본 모델보다 약간 낮음 | 정상 고객 탐지 조금 개선 |\n",
    "| **Threshold 튜닝 (Recall≥0.90, X)** | Class 1 Recall 0.8536로 목표 충족, Precision 0.9116 유지 | Balanced Acc 소폭 감소 | **목표(이탈 방지)와 Precision 균형**이 가장 적합 |\n",
    "| **Threshold 튜닝 (Max F2, X)** | Class 1 Recall 0.9739 (거의 모든 이탈 탐지) | Class 0 Recall 0.2845로 정상 고객 오탐 심각 | 운영 환경에서는 비효율적 |\n",
    "| **Threshold 튜닝 (Recall≥0.90, O)** | Class 1 Recall 0.9003 | Class 0 Recall 0.5092로 매우 낮음 | 이탈 탐지는 잘하나 정상 고객 오탐 심각 |\n",
    "| **Threshold 튜닝 (Max F2, O)** | Class 1 Recall 0.9956 (거의 100%) | Class 0 Recall 0.1131로 사실상 정상 고객 필터링 불가능 | 운영 불가능 수준 |\n",
    "\n",
    "### 3. 추천\n",
    "- **운영 환경 추천**:  \n",
    "  **기본 모델(SMOTENC X) + Threshold 튜닝(Recall ≥ 0.90)**  \n",
    "  → 이탈 고객 Recall 0.8536, Precision 0.9116로 균형 우수.\n",
    "- **분석/실험 목적**:  \n",
    "  SMOTENC 적용 모델2 (Balanced Acc 최고)도 보조 지표로 사용 가능.\n",
    "\n",
    "✅ 결론:  \n",
    "**SMOTENC 미적용 + Recall ≥ 0.90 Threshold 튜닝**이  \n",
    "운영상 Precision과 Recall 균형에서 가장 효율적."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
